{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register hook for conv1_1\n",
      "register hook for conv1_2\n",
      "register hook for pool1\n",
      "register hook for conv2_1\n",
      "register hook for conv2_2\n",
      "register hook for pool2\n",
      "register hook for conv3_1\n",
      "register hook for conv3_2\n",
      "register hook for conv3_3\n",
      "register hook for pool3\n",
      "register hook for conv4_1\n",
      "register hook for conv4_2\n",
      "register hook for conv4_3\n",
      "register hook for pool4\n",
      "register hook for conv5_1\n",
      "register hook for conv5_2\n",
      "register hook for conv5_3\n",
      "register hook for pool5\n",
      "register hook for fc6\n",
      "register hook for fc7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from vgg_face_dag import vgg_face_dag\n",
    "\n",
    "SKIP_LAYERS = [\n",
    "    'relu1_1',\n",
    "    'relu1_2',\n",
    "    'relu2_1',\n",
    "    'relu2_2',\n",
    "    'relu3_1',\n",
    "    'relu3_2',\n",
    "    'relu3_3',\n",
    "    'relu4_1',\n",
    "    'relu4_2',\n",
    "    'relu4_3',\n",
    "    'relu5_1',\n",
    "    'relu5_2',\n",
    "    'relu5_3',\n",
    "    'relu6',\n",
    "    'dropout6',\n",
    "    'relu7',\n",
    "    'dropout7',\n",
    "    'fc8',\n",
    "]\n",
    "\n",
    "device = torch.device('cuda')\n",
    "vgg_weight = './vgg_face_dag.pth'\n",
    "vgg_net = vgg_face_dag(vgg_weight)\n",
    "vgg_net.to(device)\n",
    "vgg_net.eval()\n",
    "vgg_net.register_my_hook(skip_layers=SKIP_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['leye', 'reye', 'nose', 'mouth']\n",
    "actions    = ['substitution', 'preservation']\n",
    "root_path  = '../../data/attribute_mutated/'\n",
    "base_img = '../../data/base_img.jpg'\n",
    "\n",
    "base_img_tensor = utils.get_data(base_img).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_witness(model, attri, base_img_tensor):\n",
    "    neuron_set_lists = OrderedDict()\n",
    "    org_layouts = model(base_img_tensor)\n",
    "    \n",
    "    for n,l in org_layouts.items():\n",
    "        neuron_set_lists[n] = set(range(l.shape[0]))\n",
    "    for img_name in os.listdir(root_path + attri + '_' + actions[0]):\n",
    "        attri_sub = root_path + attri + '_' + actions[0] + '/' + img_name\n",
    "        attri_pre = root_path + attri + '_' + actions[1] + '/' + img_name\n",
    "        \n",
    "        attri_sub_img_tensor = utils.get_data(attri_sub).to(device)\n",
    "        attri_pre_img_tensor = utils.get_data(attri_pre).to(device)\n",
    "        \n",
    "        attri_sub_layouts = model(attri_sub_img_tensor)\n",
    "        assert len(org_layouts) == len(attri_sub_layouts)\n",
    "        \n",
    "        for layer_idx in org_layouts.keys():\n",
    "            # print(f'strengthen computing {layer_idx}')\n",
    "            if attri_sub_layouts[layer_idx].shape != org_layouts[layer_idx].shape:\n",
    "                print(f'{layer_idx} has different shape, {attri_sub_layouts[layer_idx].shape} != {org_layouts[layer_idx].shape}')\n",
    "            if len(org_layouts[layer_idx].shape) == 1:\n",
    "                # fc layers\n",
    "                diff_layout = np.abs(attri_sub_layouts[layer_idx] - org_layouts[layer_idx])\n",
    "            else:\n",
    "                diff_layout = np.sum(np.abs(attri_sub_layouts[layer_idx] - org_layouts[layer_idx]), axis=(1,2))\n",
    "            sub_set = set([i for i,v in enumerate(diff_layout) if v > np.median(diff_layout)])\n",
    "            neuron_set_lists[layer_idx].intersection_update(sub_set) \n",
    "        \n",
    "        attri_pre_layouts = model(attri_pre_img_tensor)\n",
    "        assert len(org_layouts) == len(attri_pre_layouts)\n",
    "        \n",
    "        for layer_idx in org_layouts.keys():\n",
    "            # print(f'weaken computing {layer_idx}')\n",
    "            if len(org_layouts[layer_idx].shape) == 1:\n",
    "                # fc layers\n",
    "                diff_layout = np.abs(attri_pre_layouts[layer_idx] - org_layouts[layer_idx])\n",
    "            else:\n",
    "                diff_layout = np.sum(np.abs(attri_pre_layouts[layer_idx] - org_layouts[layer_idx]), axis=(1,2))\n",
    "            sub_set = set([i for i,v in enumerate(diff_layout) if v < np.median(diff_layout)])\n",
    "            neuron_set_lists[layer_idx].intersection_update(sub_set)\n",
    "    \n",
    "    res = []\n",
    "    for name, neuron_set in neuron_set_lists.items():\n",
    "        res.append('%s->%s' % (name, ','.join(map(str,sorted(neuron_set)))))\n",
    "        \n",
    "    print('Extracted witnesses:\\n\\t%s' % ('\\n\\t'.join(res)))\n",
    "    \n",
    "    with open(os.path.join('ami_data', f'{attri}_neurons.txt'), 'w') as out_file:\n",
    "        out_file.write('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting witnesses for leye\n",
      "\tconv1_1->\n",
      "\tconv1_2->\n",
      "\tpool1->\n",
      "\tconv2_1->\n",
      "\tconv2_2->28,58,60,102\n",
      "\tpool2->28,102\n",
      "\tconv3_1->45,185\n",
      "\tconv3_2->126\n",
      "\tconv3_3->48,52,54,93,126,135,185,207,239,246\n",
      "\tpool3->173,181,192\n",
      "\tconv4_1->95,276,323,327,412\n",
      "\tconv4_2->15,328,362\n",
      "\tconv4_3->235,246,251,272,410,448,480\n",
      "\tpool4->25,46,75,148,171,187,251,329,355,403,471\n",
      "\tconv5_1->251,497,504\n",
      "\tconv5_2->\n",
      "\tconv5_3->79\n",
      "\tpool5->145,387\n",
      "\tfc6->\n",
      "\tfc7->2384\n",
      "Extracting witnesses for reye\n",
      "\tconv1_1->\n",
      "\tconv1_2->\n",
      "\tpool1->\n",
      "\tconv2_1->\n",
      "\tconv2_2->28,58,60,102\n",
      "\tpool2->28,102\n",
      "\tconv3_1->83,169,184,185,199\n",
      "\tconv3_2->\n",
      "\tconv3_3->4,48,101,135,185,207\n",
      "\tpool3->173,182\n",
      "\tconv4_1->\n",
      "\tconv4_2->184,448\n",
      "\tconv4_3->215,235,355\n",
      "\tpool4->0,15,17,91,171,238,258,274,329,446,475\n",
      "\tconv5_1->228,409\n",
      "\tconv5_2->104\n",
      "\tconv5_3->\n",
      "\tpool5->\n",
      "\tfc6->\n",
      "\tfc7->\n",
      "Extracting witnesses for nose\n",
      "\tconv1_1->\n",
      "\tconv1_2->\n",
      "\tpool1->\n",
      "\tconv2_1->\n",
      "\tconv2_2->28,58,60,102\n",
      "\tpool2->28,102\n",
      "\tconv3_1->57,136\n",
      "\tconv3_2->\n",
      "\tconv3_3->48,101,135,174,185,200\n",
      "\tpool3->59\n",
      "\tconv4_1->327\n",
      "\tconv4_2->280,391,462\n",
      "\tconv4_3->386,472,495,496\n",
      "\tpool4->15,46,187,194,237,273,388,426,427,456,480\n",
      "\tconv5_1->1,72,177,251,386,453\n",
      "\tconv5_2->39,55,84,124,175,236,289,336\n",
      "\tconv5_3->\n",
      "\tpool5->273,353,370\n",
      "\tfc6->\n",
      "\tfc7->\n",
      "Extracting witnesses for mouth\n",
      "\tconv1_1->\n",
      "\tconv1_2->\n",
      "\tpool1->\n",
      "\tconv2_1->\n",
      "\tconv2_2->28,60,102\n",
      "\tpool2->69,102\n",
      "\tconv3_1->45,83,136,184,185,251\n",
      "\tconv3_2->45,126\n",
      "\tconv3_3->48,51,52,59,61,74,101,126,135,185,207,239\n",
      "\tpool3->12,51,59,117,132,144,151,173,182\n",
      "\tconv4_1->138,253,323,396\n",
      "\tconv4_2->15\n",
      "\tconv4_3->26,63,174,225,235,361\n",
      "\tpool4->0,15,58,82,104,105,138,149,213,235,238,273,329,330,388\n",
      "\tconv5_1->133,343\n",
      "\tconv5_2->130,267\n",
      "\tconv5_3->\n",
      "\tpool5->47,466\n",
      "\tfc6->\n",
      "\tfc7->\n"
     ]
    }
   ],
   "source": [
    "for attri in attributes:\n",
    "    print(f'Extracting witnesses for {attri}')\n",
    "    extract_witness(vgg_net, attri, base_img_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
